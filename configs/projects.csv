date,highlight,description,link
Jun-22,TabNAS,"Neural architecture search for no code users. Model that can be fed to any kind of tabular dataset. It has been generalized for both classification as well as regression tasks. Benchmarked the model for 3 datasets - two of which are classification tasks (Adult Income dataset, Car dataset) while the other is regression (Housing Prices dataset).",https://github.com/SupritiVijay/TabNAS
May-22,NERDA-Con,Python library encompassing a pipeline for training Named Entity Recognition (NER) with Large Language Models bases by incorporating the concept of Elastic Weight Consolidation (EWC) into the NER fine-tuning NERDA pipeline. Evaluated over two settings: distribution shifts and distinct tasks. The experimental results on the former shows an increase of 2.67% and and increase of 13.66% in F1 Score as compared to the naive approaches.,https://github.com/SupritiVijay/NERDA-Con
Apr-21,Sentiment Analysis using Transformers and BERT (Pytorch),"Using the IMDB Dataset, the performances of a BERT Model, a BERT model with an extra attention layer and a simple CNN model, were analysed on sentiment analysis of textual data. All of these models were coded from scratch. The accuracy obtained from a BERT Model with an extra attention layer was significantly better by 2% as compared to the workings of a normal BERT model and CNN.",
